<!-- 記事URL:https://github.com/takata150802/tech_glossary/blob/main/output/dl-overview.md# -->

## 深層学習 | Deep Learning 
- 複数の層を持つニューラルネットワークを使用してデータから特徴を自動的に学習する機械学習の一分野です。
- Deep Learning is a subfield of machine learning that uses neural networks with multiple layers to automatically learn features from data.

## ニューラルネットワーク | Neural Network 
- 単純パーセプトロン,ロジスティック回帰を多層にしたもの。
  - 多層にすることで線形分離可能でない問題を解くことができるようになった。
  - 課題はニューラルネットワークの学習の手法であったが、誤差逆伝播法が提唱され(1986年)、2010年代のDeep Learningで広く用いられることとなった。
- シグモイド関数の代わりに別の非線形関数を用いることも多く、活性化関数と呼ばれる。




## 畳み込みニューラルネットワーク | Convolutional Neural Network | CNN 
- 画像処理に特化したニューラルネットワークであり、空間的な特徴を捉えるために畳み込み層を使用します。

## リカレントニューラルネットワーク | Recurrent Neural Network | RNN 
- 時系列データやシーケンスデータを処理するために、出力を次の入力としてフィードバックする構造を持つニューラルネットワークです。

## Long Short-Term Memory | LSTM 
- リカレントニューラルネットワークの一種であり、長期間の依存関係を持つデータを効率的に学習することができます。

## 敵対的生成ネットワーク | Generative Adversarial Network | GAN 
- 生成モデルと識別モデルが競い合うことで高品質なデータを生成するモデルです。

## Deepfake 

## Seq2Seq Model | Sequence-to-Sequence Model 

## 変分オートエンコーダー | Variational Autoencoder | VAE 
- データの潜在変数を学習し、新しいデータの生成や再構成を行う生成モデルの一種です。

## 転移学習 | Transfer Learning 

## fine-Tuning 

## Q-Learning 
- エージェントが環境からの報酬に基づいて最適な行動を学習する強化学習アルゴリズムです。

## アテンション機構 | Attention Mechanism 

## トランスフォーマー | Transformer 
- アテンション機構を用いて自然言語処理において高い性能を発揮するモデルです。

## Deep Q-Network | DQN 
- ディープラーニングを用いたQ-Learningの実装であり、エージェントが複雑な環境で最適な行動を学習するために使用されます。

## One-shot Learning 
- 少ないサンプルで学習を行うことができる技術です。

## Zero-shot Learning 
- 学習に使用していないクラスを識別することができる技術です。

## プロンプトエンジニアリング | Prompt Engineering 
- 生成モデルに対する入力（プロンプト）を最適化して望ましい出力を得る技術です。

## EMアルゴリズム | Expectation-Maximization Algorithm | EM Algorithm 

## 拡散モデル | Diffusion Model 
