<!-- 記事URL:https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md# -->

## 機械学習 | Machine Learning<a id="5qmf5qKw5a2m57+SIHwgTWFjaGluZSBMZWFybmluZw=="></a>

- データからパターンを学習し、予測や意思決定を行うアルゴリズムや手法のことです。

## 教師あり学習 | Supervised Learning<a id="5pWZ5bir44GC44KK5a2m57+SIHwgU3VwZXJ2aXNlZCBMZWFybmluZw=="></a>

- 入力データとそれに対応する正解ラベルを用いてモデルを訓練する学習方法です。

## 教師なし学習 | Unsupervised Learning<a id="5pWZ5bir44Gq44GX5a2m57+SIHwgVW5zdXBlcnZpc2VkIExlYXJuaW5n"></a>

- ラベルのないデータからパターンや構造を見つけ出す学習方法です。

## 強化学習 | Reinforcement Learning<a id="5by35YyW5a2m57+SIHwgUmVpbmZvcmNlbWVudCBMZWFybmluZw=="></a>

- エージェントが環境との相互作用を通じて報酬を最大化する行動を学習する方法です。

## 分類 | Classification<a id="5YiG6aGeIHwgQ2xhc3NpZmljYXRpb24="></a>

- データをあらかじめ定義されたカテゴリに<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#5YiG6aGeIHwgQ2xhc3NpZmljYXRpb24=">分類</a>する<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#5qmf5qKw5a2m57+SIHwgTWFjaGluZSBMZWFybmluZw==">機械学習</a>タスクです。

## 回帰 | Regression<a id="5Zue5biwIHwgUmVncmVzc2lvbg=="></a>

- 連続値を予測する<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#5qmf5qKw5a2m57+SIHwgTWFjaGluZSBMZWFybmluZw==">機械学習</a>タスク

## 重回帰 | Multiple Regression<a id="6YeN5Zue5biwIHwgTXVsdGlwbGUgUmVncmVzc2lvbg=="></a>

- 複数の独立変数を用いて従属変数を予測する<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#5Zue5biwIHwgUmVncmVzc2lvbg==">回帰</a>分析の一種

## サポートベクターマシン | Support Vector Machine | SVM<a id="44K144Od44O844OI44OZ44Kv44K/44O844Oe44K344OzIHwgU3VwcG9ydCBWZWN0b3IgTWFjaGluZSB8IFNWTQ=="></a>

- データポイントを分離する最適なハイパープレーンを見つける<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#5YiG6aGeIHwgQ2xhc3NpZmljYXRpb24=">分類</a>アルゴリズムです。

## クラスタリング | Clustering<a id="44Kv44Op44K544K/44Oq44Oz44KwIHwgQ2x1c3RlcmluZw=="></a>

- データを類似したグループ（クラスタ）に分ける<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#5pWZ5bir44Gq44GX5a2m57+SIHwgVW5zdXBlcnZpc2VkIExlYXJuaW5n">教師なし学習</a>の手法です。

## 主成分分析 | Principal Component Analysis | PCA<a id="5Li75oiQ5YiG5YiG5p6QIHwgUHJpbmNpcGFsIENvbXBvbmVudCBBbmFseXNpcyB8IFBDQQ=="></a>

- 高次元データを低次元に変換する<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#5qyh5YWD5YmK5ribIHwgRGltZW5zaW9uYWxpdHkgUmVkdWN0aW9u">次元削減</a>の手法です。

## 次元削減 | Dimensionality Reduction<a id="5qyh5YWD5YmK5ribIHwgRGltZW5zaW9uYWxpdHkgUmVkdWN0aW9u"></a>

- 高次元データをより少ない次元に圧縮して、情報の損失を最小限に抑える手法です。

## 正規化 | Normalization<a id="5q2j6KaP5YyWIHwgTm9ybWFsaXphdGlvbg=="></a>

- データの[最小値, 最大値]が[0, 1] や[-1, 1]あるいは[0,255] となるように変換するといった、後続の計算処理に都合が良いようにデータをスケーリングすること

## 標準化 | Standardization<a id="5qiZ5rqW5YyWIHwgU3RhbmRhcmRpemF0aW9u"></a>

- データの平均が0, 分散が1となるように変換すること

## コンピュータビジョン | Computer Vision | CV<a id="44Kz44Oz44OU44Ol44O844K/44OT44K444On44OzIHwgQ29tcHV0ZXIgVmlzaW9uIHwgQ1Y="></a>

- 画像や動画から有用な情報を抽出する技術分野です。

## セグメンテーション | Segmentation<a id="44K744Kw44Oh44Oz44OG44O844K344On44OzIHwgU2VnbWVudGF0aW9u"></a>

- 画像をピクセル単位でカテゴリに分けるプロセスです。

## 特徴量<a id="54m55b606YeP"></a>

- 生データの性質や意味を良く表現し、後続の計算処理に利用しやすい形式に変換されたデータ。

## 物体検出 | Object Detection<a id="54mp5L2T5qSc5Ye6IHwgT2JqZWN0IERldGVjdGlvbg=="></a>

- 画像内の複数の物体を検出し、その位置とカテゴリを特定する技術です。

## 自然言語処理 | Natural Language Processing | NLP<a id="6Ieq54S26KiA6Kqe5Yem55CGIHwgTmF0dXJhbCBMYW5ndWFnZSBQcm9jZXNzaW5nIHwgTkxQ"></a>

- 人間の言語を理解し、生成するコンピュータの能力を研究する分野です。

## 音声認識 | Speech Recognition<a id="6Z+z5aOw6KqN6K2YIHwgU3BlZWNoIFJlY29nbml0aW9u"></a>

- 音声信号をテキストに変換する技術です。

## k-means<a id="ay1tZWFucw=="></a>

- データをk個のクラスタに分ける<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#44Kv44Op44K544K/44Oq44Oz44KwIHwgQ2x1c3RlcmluZw==">クラスタリング</a>アルゴリズムです。

## カーネルトリック | Kernel Trick<a id="44Kr44O844ON44Or44OI44Oq44OD44KvIHwgS2VybmVsIFRyaWNr"></a>

- 非線形データを線形に分離可能な高次元空間に変換する手法です。

## ランダムフォレスト | Random Forest<a id="44Op44Oz44OA44Og44OV44Kp44Os44K544OIIHwgUmFuZG9tIEZvcmVzdA=="></a>

- 複数の決定木を組み合わせて予測を行うアンサンブル学習アルゴリズムです。

## 自己組織化マップ | Self-Organizing Map | SOM<a id="6Ieq5bex57WE57mU5YyW44Oe44OD44OXIHwgU2VsZi1Pcmdhbml6aW5nIE1hcCB8IFNPTQ=="></a>

- 高次元データを低次元空間にマッピングする<a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#5pWZ5bir44Gq44GX5a2m57+SIHwgVW5zdXBlcnZpc2VkIExlYXJuaW5n">教師なし学習</a>の<a href="https://github.com/takata150802/tech_glossary/blob/main/output/dl-overview.md#44OL44Ol44O844Op44Or44ON44OD44OI44Ov44O844KvIHwgTmV1cmFsIE5ldHdvcms=">ニューラルネットワーク</a>です。

## 汎化誤差 | Generalization Error<a id="5rGO5YyW6Kqk5beuIHwgR2VuZXJhbGl6YXRpb24gRXJyb3I="></a>

- <a href="https://github.com/takata150802/tech_glossary/blob/main/output/dl-train_eval.md#6KiT57e044OH44O844K/IHwg44OI44Os44O844OL44Oz44Kw44OH44O844K/IHwgVHJhaW5pbmcgRGF0YQ==">訓練データ</a>に無いサンプルに対する誤差
- 以下3つから構成されるものと考える
  - <a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#44OQ44Kk44Ki44K56Kqk5beuIHwgQmlhcyBFcnJvcg==">バイアス誤差</a>
  - <a href="https://github.com/takata150802/tech_glossary/blob/main/output/ml-overview.md#44OQ44Oq44Ki44Oz44K56Kqk5beuIHwgVmFyaWFuY2UgRXJyb3I=">バリアンス誤差</a>
  - ノイズ ・・・モデル集合の選択に依存せず，本質的に減らせない真のモデルのばらつき

## 標本誤差 | Sample Error<a id="5qiZ5pys6Kqk5beuIHwgU2FtcGxlIEVycm9y"></a>

- <a href="https://github.com/takata150802/tech_glossary/blob/main/output/dl-train_eval.md#6KiT57e044OH44O844K/IHwg44OI44Os44O844OL44Oz44Kw44OH44O844K/IHwgVHJhaW5pbmcgRGF0YQ==">訓練データ</a>のサンプルに対する誤差
- 「経験誤差 | empirical error」や「経験損失 | empirical risk」ともいう

```math
標本誤差: R_{emp}(\theta) = 1/N \sigma_{i=1}^{N}L(x_i,\theta) \\
損失関数: L(x,\theta) \\
データ: D={x_1,...,x_N} 
```

## バイアス誤差 | Bias Error<a id="44OQ44Kk44Ki44K56Kqk5beuIHwgQmlhcyBFcnJvcg=="></a>

- 候補モデル集合に真のモデルは含まれないことで生じる誤差

## バリアンス誤差 | Variance Error<a id="44OQ44Oq44Ki44Oz44K56Kqk5beuIHwgVmFyaWFuY2UgRXJyb3I="></a>

- <a href="https://github.com/takata150802/tech_glossary/blob/main/output/dl-train_eval.md#6KiT57e044OH44O844K/IHwg44OI44Os44O844OL44Oz44Kw44OH44O844K/IHwgVHJhaW5pbmcgRGF0YQ==">訓練データ</a>が異なると，異なる予測モデルが選択されることで生じる誤差
